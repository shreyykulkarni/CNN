# -*- coding: utf-8 -*-
"""CIFAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EutNhC7QwQrnr1AImhYFqzdRV4UTCHbg
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from keras.utils import to_categorical
from keras.preprocessing.image import  ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import regularizers
from keras.regularizers import l2
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.layers import BatchNormalization
from keras import regularizers
from keras.optimizers import SGD
from keras.optimizers import Adam
from keras.optimizers import RMSprop
from keras import backend as K
from keras.preprocessing import image
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from keras.preprocessing.image import ImageDataGenerator
plt.figure(dpi=300)
plt.figure(dpi=300)



def prep_dataset():
    CIFAR = keras.datasets.cifar10
    (X_train,Y_train) , (X_test, Y_test) = CIFAR.load_data()

    X_train = X_train.reshape((X_train.shape[0], 32, 32, 3))
    X_test = X_test.reshape((X_test.shape[0], 32, 32, 3))

    Y_train = to_categorical(Y_train)
    Y_test = to_categorical(Y_test)

    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')

    X_train = X_train/255.0 
    X_test = X_test/255.0  
    
    return X_train, Y_train, X_test, Y_test



def model_description():
  model = Sequential()
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',padding='same', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001),input_shape=(32, 32, 3)))
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',padding='same', kernel_regularizer=l2(0.001),bias_regularizer=l2(0.001)))
  model.add(BatchNormalization())
  model.add(MaxPooling2D((2, 2)))
  model.add(Dropout(0.3))
  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001),bias_regularizer=l2(0.001)))
  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001)))
  model.add(BatchNormalization())
  model.add(MaxPooling2D((2, 2)))
  model.add(Dropout(0.3))
  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001),bias_regularizer=l2(0.001)))
  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Dropout(0.5))
  model.add(Flatten())
  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
  model.add(Dense(10, activation='softmax'))
  opt1 = SGD(lr=0.001, momentum=0.9)
  opt2 = Adam(learning_rate = 0.0005)
  opt3 = RMSprop(lr=0.001, momentum=0.9,epsilon=1e-04)
  model.compile(optimizer=opt2, loss='categorical_crossentropy', metrics=['accuracy'])
  model.summary()
  return model



def model_evaluation(X_train, Y_train,X_test, Y_test):
    M = []
    model = model_description() 
    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
    # prepare iterator
    it_train = datagen.flow(X_train, Y_train, batch_size=64)
    # fit model
    steps = int(X_train.shape[0] /200)
    history = model.fit(X_train, Y_train, epochs=110, batch_size=64, validation_data=(X_test, Y_test), verbose=2)
    _, acc = model.evaluate(X_test, Y_test, verbose=2)
    print('> %.3f' % (acc * 100.0))
    M.append(history)
    return acc, M



def illustrations(M):
    for i in range(len(M)):
        plt.title('Classification Loss')
        plt.plot(M[i].history['loss'], color='dodgerblue',label = "Train_acc", linewidth=3.0 ) 
        plt.plot(M[i].history['val_loss'], color='crimson',label = "Train_acc", linewidth=3.0 )
        plt.legend(loc='best')
        plt.xlabel('Epochs') 
        plt.ylabel('Accuracy')
    plt.show()
    plt.figure(dpi=300)

    for i in range(len(M)):  
        plt.title('Classification Accuracy- ADAM ')
        plt.plot(M[i].history['accuracy'], color='dodgerblue', label = "Train_acc", linewidth=3.0 ) 
        plt.plot(M[i].history['val_accuracy'], color='crimson', label = "Val_acc", linewidth=3.0 )
        plt.legend(loc='best')
        plt.xlabel('Epochs') 
        plt.ylabel('Accuracy')
    plt.show()
    plt.figure(dpi=300)


    print("******Max Training Acc******\n", max(M[i].history['accuracy']))
    print("******Max Validation Acc******\n", max(M[i].history['val_accuracy']))
    
    df = pd.DataFrame(M[i].history['accuracy']) 
    df.to_excel('output.xlsx',sheet_name='Sheet_name_1', header=True, index=True)

    df = pd.DataFrame(M[i].history['accuracy']) 
    df.to_excel('output.xlsx',sheet_name='Sheet_name_2', header=True, index=True)
    
    
def run_model():
    X_train, Y_train, X_test, Y_test = prep_dataset()
    accuracies, M = model_evaluation(X_train, Y_train,X_test, Y_test)
    illustrations(M)
 
run_model()

import keras
from graphviz import render
import json
from ann_visualizer.visualize import ann_viz
from graphviz import Source

#render('dot', 'png', 'fname.dot')

model = model_description()
ann_viz(
  model, 
  view=True, 
  filename="network.gv",
  title="CNN architecture for MNIST"
)
graph_source = Source.from_file('network.gv',format='png')
graph_source